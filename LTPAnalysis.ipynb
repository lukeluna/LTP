{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84da6472-7b1d-4e7a-a7e8-80a81a71560a",
   "metadata": {},
   "source": [
    "## LTP Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0191df16-24ef-4420-bc3d-186ed6a8d095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc51e13a-6c74-4f12-9ea0-ef1fc05a0b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def level_1_mapping(column):\n",
    "    level_1 = {\n",
    "        'hasty generalization': 'fallacy of logic',\n",
    "        'slippery slope': 'fallacy of logic',\n",
    "        'causal oversimplification': 'fallacy of logic',\n",
    "        'appeal to ridicule': 'appeal to emotion',\n",
    "        'appeal to nature': 'fallacy of credibility',\n",
    "        'false causality': 'fallacy of logic',\n",
    "        'ad populum': 'fallacy of credibility',\n",
    "        'ad hominem': 'fallacy of credibility',\n",
    "        'false analogy': 'fallacy of logic',\n",
    "        'false dilemma': 'fallacy of credibility',\n",
    "        'appeal to fear': 'appeal to emotion',\n",
    "        'appeal to authority': 'fallacy of credibility',\n",
    "        'appeal to worse problem': 'appeal to emotion',\n",
    "        'circular reasoning': 'fallacy of logic',\n",
    "        'guilt by association': 'fallacy of credibility',\n",
    "        'appeal to anger': 'appeal to emotion',\n",
    "        'straw man': 'fallacy of logic',\n",
    "        'appeal to tradition': 'fallacy of credibility',\n",
    "        'equivocation': 'fallacy of logic',\n",
    "        'fallacy of division': 'fallacy of logic',\n",
    "        'tu quoque': 'fallacy of credibility',\n",
    "        'appeal to positive emotion': 'appeal to emotion',\n",
    "        'appeal to pity': 'appeal to emotion',\n",
    "        'appeal to emotion (level 1)': 'appeal to emotion'\n",
    "\n",
    "    }\n",
    "    return column.map(level_1).fillna(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "223bc0a4-6695-41ef-a3bf-c16099ac2654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def level_0_mapping(column):\n",
    "    level_0 = {\n",
    "        'hasty generalization': 'fallacy detected',\n",
    "        'slippery slope': 'fallacy detected',\n",
    "        'causal oversimplification': 'fallacy detected',\n",
    "        'appeal to ridicule': 'fallacy detected',\n",
    "        'appeal to nature': 'fallacy detected',\n",
    "        'false causality': 'fallacy detected',\n",
    "        'ad populum': 'fallacy detected',\n",
    "        'ad hominem': 'fallacy detected',\n",
    "        'false analogy': 'fallacy detected',\n",
    "        'false dilemma': 'fallacy detected',\n",
    "        'appeal to fear': 'fallacy detected',\n",
    "        'appeal to authority': 'fallacy detected',\n",
    "        'appeal to worse problem': 'fallacy detected',\n",
    "        'circular reasoning': 'fallacy detected',\n",
    "        'guilt by association': 'fallacy detected',\n",
    "        'appeal to anger': 'fallacy detected',\n",
    "        'strawman': 'fallacy detected',\n",
    "        'appeal to tradition': 'fallacy detected',\n",
    "        'equivocation': 'fallacy detected',\n",
    "        'fallacy of division': 'fallacy detected',\n",
    "        'tu quoque': 'fallacy detected',\n",
    "        'appeal to positive emotion': 'fallacy detected',\n",
    "        'appeal to pity': 'fallacy detected',\n",
    "        'appeal to emotion (level 1)': 'fallacy detected'\n",
    "    }\n",
    "\n",
    "    return column.map(level_0).fillna('no fallacy detected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ecca9c1-4570-4fd6-b43c-1c76d46449f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>expected_label</th>\n",
       "      <th>actual_label</th>\n",
       "      <th>result</th>\n",
       "      <th>canonical</th>\n",
       "      <th>expected_label_level1</th>\n",
       "      <th>expected_label_level0</th>\n",
       "      <th>canonical_level1</th>\n",
       "      <th>canonical_level0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I keep seeing if an adventure mode needs to ex...</td>\n",
       "      <td>slippery slope</td>\n",
       "      <td>answer: appeal to emotional manipulation.\\n\\nt...</td>\n",
       "      <td>False</td>\n",
       "      <td>no match</td>\n",
       "      <td>fallacy of logic</td>\n",
       "      <td>fallacy detected</td>\n",
       "      <td>no match</td>\n",
       "      <td>no fallacy detected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>That leads to me believe that most cat lovers ...</td>\n",
       "      <td>hasty generalization</td>\n",
       "      <td>answer: appeal to stereotype.\\n\\nthe premise s...</td>\n",
       "      <td>False</td>\n",
       "      <td>no match</td>\n",
       "      <td>fallacy of logic</td>\n",
       "      <td>fallacy detected</td>\n",
       "      <td>no match</td>\n",
       "      <td>no fallacy detected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Someone once told me they have an\"alt\" cause t...</td>\n",
       "      <td>false analogy</td>\n",
       "      <td>answer: straw man fallacy.\\n\\nthe person has m...</td>\n",
       "      <td>False</td>\n",
       "      <td>straw man</td>\n",
       "      <td>fallacy of logic</td>\n",
       "      <td>fallacy detected</td>\n",
       "      <td>fallacy of logic</td>\n",
       "      <td>no fallacy detected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Joe Biden will lose to Trump if he is the nomi...</td>\n",
       "      <td>guilt by association</td>\n",
       "      <td>answer: appeal to pity.\\n\\nthe author suggests...</td>\n",
       "      <td>False</td>\n",
       "      <td>appeal to pity</td>\n",
       "      <td>fallacy of credibility</td>\n",
       "      <td>fallacy detected</td>\n",
       "      <td>appeal to emotion</td>\n",
       "      <td>fallacy detected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Joe Biden will lose to Trump if he is the nomi...</td>\n",
       "      <td>causal oversimplification</td>\n",
       "      <td>answer: appeal to anger.\\n\\nthe text relies on...</td>\n",
       "      <td>False</td>\n",
       "      <td>appeal to anger</td>\n",
       "      <td>fallacy of logic</td>\n",
       "      <td>fallacy detected</td>\n",
       "      <td>appeal to emotion</td>\n",
       "      <td>fallacy detected</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  \\\n",
       "0           0  I keep seeing if an adventure mode needs to ex...   \n",
       "1           1  That leads to me believe that most cat lovers ...   \n",
       "2           2  Someone once told me they have an\"alt\" cause t...   \n",
       "3           3  Joe Biden will lose to Trump if he is the nomi...   \n",
       "4           4  Joe Biden will lose to Trump if he is the nomi...   \n",
       "\n",
       "              expected_label  \\\n",
       "0             slippery slope   \n",
       "1       hasty generalization   \n",
       "2              false analogy   \n",
       "3       guilt by association   \n",
       "4  causal oversimplification   \n",
       "\n",
       "                                        actual_label  result        canonical  \\\n",
       "0  answer: appeal to emotional manipulation.\\n\\nt...   False         no match   \n",
       "1  answer: appeal to stereotype.\\n\\nthe premise s...   False         no match   \n",
       "2  answer: straw man fallacy.\\n\\nthe person has m...   False        straw man   \n",
       "3  answer: appeal to pity.\\n\\nthe author suggests...   False   appeal to pity   \n",
       "4  answer: appeal to anger.\\n\\nthe text relies on...   False  appeal to anger   \n",
       "\n",
       "    expected_label_level1 expected_label_level0   canonical_level1  \\\n",
       "0        fallacy of logic      fallacy detected           no match   \n",
       "1        fallacy of logic      fallacy detected           no match   \n",
       "2        fallacy of logic      fallacy detected   fallacy of logic   \n",
       "3  fallacy of credibility      fallacy detected  appeal to emotion   \n",
       "4        fallacy of logic      fallacy detected  appeal to emotion   \n",
       "\n",
       "      canonical_level0  \n",
       "0  no fallacy detected  \n",
       "1  no fallacy detected  \n",
       "2  no fallacy detected  \n",
       "3     fallacy detected  \n",
       "4     fallacy detected  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'canonical/results_canonical_spans/results-cot-mafalda-spans-gemma_canonical.csv'  # Replace with the actual file path\n",
    "results = pd.read_csv(file_path)\n",
    "\n",
    "# Map actual_label column using the level_1 dictionary\n",
    "results['expected_label_level1'] =  level_1_mapping(results['expected_label'])\n",
    "results['expected_label_level0'] = level_0_mapping(results['expected_label'])\n",
    "results['canonical_level1'] = level_1_mapping(results['canonical'])\n",
    "results['canonical_level0'] = level_0_mapping(results['canonical'])\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dffc8b3-1bea-4e35-9178-88125d3f2dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc(expected, canonical, method='weighted'):\n",
    "    expected_labels = expected\n",
    "    processed_labels  = canonical\n",
    "    \n",
    "    accuracy = accuracy_score(expected_labels, processed_labels)\n",
    "    precision = precision_score(expected_labels, processed_labels, average=method)  # adjust average method as necessary\n",
    "    recall = recall_score(expected_labels, processed_labels, average=method)  # adjust average method as necessary\n",
    "    f1 = f1_score(expected_labels, processed_labels, average=method)  # adjust average method as necessary\n",
    "\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bad3574f-cee2-4710-a249-64a6dfe675b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rizkiduwinanto/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/rizkiduwinanto/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/rizkiduwinanto/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/rizkiduwinanto/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/rizkiduwinanto/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/rizkiduwinanto/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/rizkiduwinanto/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/rizkiduwinanto/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/rizkiduwinanto/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/rizkiduwinanto/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/rizkiduwinanto/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/rizkiduwinanto/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/rizkiduwinanto/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/rizkiduwinanto/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/rizkiduwinanto/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/rizkiduwinanto/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/rizkiduwinanto/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/rizkiduwinanto/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/rizkiduwinanto/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/rizkiduwinanto/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/rizkiduwinanto/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/rizkiduwinanto/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/rizkiduwinanto/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/rizkiduwinanto/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/rizkiduwinanto/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/rizkiduwinanto/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/rizkiduwinanto/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/rizkiduwinanto/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/rizkiduwinanto/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/rizkiduwinanto/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "level_0_res = pd.DataFrame()\n",
    "level_1_res = pd.DataFrame()\n",
    "\n",
    "method = 'weighted'        \n",
    "\n",
    "for prompting_technique in ['cot', 'cot-sc', 'rar-1', 'rar-2', 'tot']:\n",
    "    for model in ['gemma', 'mistral', 'openchat']:\n",
    "        file_path = 'canonical/results_canonical_spans/results-{}-mafalda-spans-{}_canonical.csv'.format(prompting_technique, model)\n",
    "        results = pd.read_csv(file_path)\n",
    "        \n",
    "        results['expected_label_level1'] =  level_1_mapping(results['expected_label'])\n",
    "        results['expected_label_level0'] = level_0_mapping(results['expected_label'])\n",
    "        results['canonical_level1'] = level_1_mapping(results['canonical'])\n",
    "        results['canonical_level0'] = level_0_mapping(results['canonical'])\n",
    "\n",
    "        expected_labels_level_0 = results['expected_label_level0']\n",
    "        processed_labels_level_0  = results['canonical_level0']\n",
    "        \n",
    "        accuracy_level_0, precision_level_0, recall_level_0, f1_level_0 = calc(expected_labels_level_0, processed_labels_level_0, method)\n",
    "\n",
    "        level_0_res = level_0_res._append({\n",
    "            'model': model,\n",
    "            'prompting_technique': prompting_technique,\n",
    "            'accuracy': accuracy_level_0,\n",
    "            'precision': precision_level_0,\n",
    "            'recall': recall_level_0,\n",
    "            'f1': f1_level_0\n",
    "        }, ignore_index=True)\n",
    "\n",
    "        expected_labels_level_1 = results['expected_label_level1']\n",
    "        processed_labels_level_1 = results['canonical_level1']\n",
    "        \n",
    "        accuracy_level_1, precision_level_1, recall_level_1, f1_level_1 = calc(expected_labels_level_1, processed_labels_level_1, method)\n",
    "\n",
    "        level_1_res = level_1_res._append({\n",
    "            'model': model,\n",
    "            'prompting_technique': prompting_technique,\n",
    "            'accuracy': accuracy_level_1,\n",
    "            'precision': precision_level_1,\n",
    "            'recall': recall_level_1,\n",
    "            'f1': f1_level_1\n",
    "        }, ignore_index=True)\n",
    "\n",
    "level_0_res.to_csv(\"results/level-0-spans.csv\", sep=\",\")\n",
    "level_1_res.to_csv(\"results/level-1-spans.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5bbe0e05-ae28-4ddc-8e1a-33c0724ec489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>prompting_technique</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gemma</td>\n",
       "      <td>cot</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.655242</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.560276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mistral</td>\n",
       "      <td>cot</td>\n",
       "      <td>0.638211</td>\n",
       "      <td>0.703953</td>\n",
       "      <td>0.638211</td>\n",
       "      <td>0.657696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>openchat</td>\n",
       "      <td>cot</td>\n",
       "      <td>0.551570</td>\n",
       "      <td>0.722928</td>\n",
       "      <td>0.551570</td>\n",
       "      <td>0.568921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gemma</td>\n",
       "      <td>cot-sc</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.643748</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.556512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mistral</td>\n",
       "      <td>cot-sc</td>\n",
       "      <td>0.669604</td>\n",
       "      <td>0.716168</td>\n",
       "      <td>0.669604</td>\n",
       "      <td>0.683938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>openchat</td>\n",
       "      <td>cot-sc</td>\n",
       "      <td>0.506726</td>\n",
       "      <td>0.710263</td>\n",
       "      <td>0.506726</td>\n",
       "      <td>0.518113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gemma</td>\n",
       "      <td>rar-1</td>\n",
       "      <td>0.673554</td>\n",
       "      <td>0.675142</td>\n",
       "      <td>0.673554</td>\n",
       "      <td>0.674337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mistral</td>\n",
       "      <td>rar-1</td>\n",
       "      <td>0.721739</td>\n",
       "      <td>0.660641</td>\n",
       "      <td>0.721739</td>\n",
       "      <td>0.656442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>openchat</td>\n",
       "      <td>rar-1</td>\n",
       "      <td>0.692641</td>\n",
       "      <td>0.691119</td>\n",
       "      <td>0.692641</td>\n",
       "      <td>0.691867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gemma</td>\n",
       "      <td>rar-2</td>\n",
       "      <td>0.599206</td>\n",
       "      <td>0.628112</td>\n",
       "      <td>0.599206</td>\n",
       "      <td>0.611900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mistral</td>\n",
       "      <td>rar-2</td>\n",
       "      <td>0.720339</td>\n",
       "      <td>0.671824</td>\n",
       "      <td>0.720339</td>\n",
       "      <td>0.657734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>openchat</td>\n",
       "      <td>rar-2</td>\n",
       "      <td>0.708000</td>\n",
       "      <td>0.709621</td>\n",
       "      <td>0.708000</td>\n",
       "      <td>0.708800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gemma</td>\n",
       "      <td>tot</td>\n",
       "      <td>0.522321</td>\n",
       "      <td>0.666314</td>\n",
       "      <td>0.522321</td>\n",
       "      <td>0.543082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mistral</td>\n",
       "      <td>tot</td>\n",
       "      <td>0.633621</td>\n",
       "      <td>0.679418</td>\n",
       "      <td>0.633621</td>\n",
       "      <td>0.648512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>openchat</td>\n",
       "      <td>tot</td>\n",
       "      <td>0.493333</td>\n",
       "      <td>0.728282</td>\n",
       "      <td>0.493333</td>\n",
       "      <td>0.496276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model prompting_technique  accuracy  precision    recall        f1\n",
       "0      gemma                 cot  0.535714   0.655242  0.535714  0.560276\n",
       "1    mistral                 cot  0.638211   0.703953  0.638211  0.657696\n",
       "2   openchat                 cot  0.551570   0.722928  0.551570  0.568921\n",
       "3      gemma              cot-sc  0.531250   0.643748  0.531250  0.556512\n",
       "4    mistral              cot-sc  0.669604   0.716168  0.669604  0.683938\n",
       "5   openchat              cot-sc  0.506726   0.710263  0.506726  0.518113\n",
       "6      gemma               rar-1  0.673554   0.675142  0.673554  0.674337\n",
       "7    mistral               rar-1  0.721739   0.660641  0.721739  0.656442\n",
       "8   openchat               rar-1  0.692641   0.691119  0.692641  0.691867\n",
       "9      gemma               rar-2  0.599206   0.628112  0.599206  0.611900\n",
       "10   mistral               rar-2  0.720339   0.671824  0.720339  0.657734\n",
       "11  openchat               rar-2  0.708000   0.709621  0.708000  0.708800\n",
       "12     gemma                 tot  0.522321   0.666314  0.522321  0.543082\n",
       "13   mistral                 tot  0.633621   0.679418  0.633621  0.648512\n",
       "14  openchat                 tot  0.493333   0.728282  0.493333  0.496276"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level_0_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95820768-475c-4cbe-ad54-672451ac7ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gemma</th>\n",
       "      <td>0.572409</td>\n",
       "      <td>0.653712</td>\n",
       "      <td>0.572409</td>\n",
       "      <td>0.589222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistral</th>\n",
       "      <td>0.676703</td>\n",
       "      <td>0.686401</td>\n",
       "      <td>0.676703</td>\n",
       "      <td>0.660864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openchat</th>\n",
       "      <td>0.590454</td>\n",
       "      <td>0.712443</td>\n",
       "      <td>0.590454</td>\n",
       "      <td>0.596795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy  precision    recall        f1\n",
       "model                                            \n",
       "gemma     0.572409   0.653712  0.572409  0.589222\n",
       "mistral   0.676703   0.686401  0.676703  0.660864\n",
       "openchat  0.590454   0.712443  0.590454  0.596795"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level_0_model = level_0_res.groupby('model')[['accuracy', 'precision', 'recall', 'f1']].mean()\n",
    "level_0_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f05e447-9654-423f-9e8a-ac3140bebd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "level_0_model.to_csv(\"results/level-0-model-spans.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5ec760c-5f97-4b56-860e-d878f0c8627c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gemma</th>\n",
       "      <td>0.315348</td>\n",
       "      <td>0.500211</td>\n",
       "      <td>0.315348</td>\n",
       "      <td>0.340250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistral</th>\n",
       "      <td>0.418508</td>\n",
       "      <td>0.419074</td>\n",
       "      <td>0.418508</td>\n",
       "      <td>0.393865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openchat</th>\n",
       "      <td>0.336771</td>\n",
       "      <td>0.503197</td>\n",
       "      <td>0.336771</td>\n",
       "      <td>0.344881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy  precision    recall        f1\n",
       "model                                            \n",
       "gemma     0.315348   0.500211  0.315348  0.340250\n",
       "mistral   0.418508   0.419074  0.418508  0.393865\n",
       "openchat  0.336771   0.503197  0.336771  0.344881"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level_1_model = level_1_res.groupby('model')[['accuracy', 'precision', 'recall', 'f1']].mean()\n",
    "level_1_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d2cbf34-7a0d-412d-aec4-6a960df9e890",
   "metadata": {},
   "outputs": [],
   "source": [
    "level_1_model.to_csv(\"results/level-1-model-spans.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c1b2364-7d73-47ff-8fe1-976fee1e42a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prompting_technique</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cot</th>\n",
       "      <td>0.575165</td>\n",
       "      <td>0.694041</td>\n",
       "      <td>0.575165</td>\n",
       "      <td>0.595631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cot-sc</th>\n",
       "      <td>0.569193</td>\n",
       "      <td>0.690060</td>\n",
       "      <td>0.569193</td>\n",
       "      <td>0.586187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rar-1</th>\n",
       "      <td>0.695978</td>\n",
       "      <td>0.675634</td>\n",
       "      <td>0.695978</td>\n",
       "      <td>0.674215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rar-2</th>\n",
       "      <td>0.675848</td>\n",
       "      <td>0.669853</td>\n",
       "      <td>0.675848</td>\n",
       "      <td>0.659478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tot</th>\n",
       "      <td>0.549758</td>\n",
       "      <td>0.691338</td>\n",
       "      <td>0.549758</td>\n",
       "      <td>0.562623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     accuracy  precision    recall        f1\n",
       "prompting_technique                                         \n",
       "cot                  0.575165   0.694041  0.575165  0.595631\n",
       "cot-sc               0.569193   0.690060  0.569193  0.586187\n",
       "rar-1                0.695978   0.675634  0.695978  0.674215\n",
       "rar-2                0.675848   0.669853  0.675848  0.659478\n",
       "tot                  0.549758   0.691338  0.549758  0.562623"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level_0_prompt = level_0_res.groupby('prompting_technique')[['accuracy', 'precision', 'recall', 'f1']].mean()\n",
    "level_0_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7738c65c-58ab-4da7-b84e-7ff3877d191c",
   "metadata": {},
   "outputs": [],
   "source": [
    "level_0_prompt.to_csv(\"results/level-0-prompt-spans.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ab23fc7-6a0b-498e-84da-844dd0cbd9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prompting_technique</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cot</th>\n",
       "      <td>0.291485</td>\n",
       "      <td>0.506443</td>\n",
       "      <td>0.291485</td>\n",
       "      <td>0.312077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cot-sc</th>\n",
       "      <td>0.306607</td>\n",
       "      <td>0.550103</td>\n",
       "      <td>0.306607</td>\n",
       "      <td>0.334341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rar-1</th>\n",
       "      <td>0.455601</td>\n",
       "      <td>0.433166</td>\n",
       "      <td>0.455601</td>\n",
       "      <td>0.421074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rar-2</th>\n",
       "      <td>0.428986</td>\n",
       "      <td>0.408422</td>\n",
       "      <td>0.428986</td>\n",
       "      <td>0.402823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tot</th>\n",
       "      <td>0.301700</td>\n",
       "      <td>0.472669</td>\n",
       "      <td>0.301700</td>\n",
       "      <td>0.328012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     accuracy  precision    recall        f1\n",
       "prompting_technique                                         \n",
       "cot                  0.291485   0.506443  0.291485  0.312077\n",
       "cot-sc               0.306607   0.550103  0.306607  0.334341\n",
       "rar-1                0.455601   0.433166  0.455601  0.421074\n",
       "rar-2                0.428986   0.408422  0.428986  0.402823\n",
       "tot                  0.301700   0.472669  0.301700  0.328012"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level_1_prompt = level_1_res.groupby('prompting_technique')[['accuracy', 'precision', 'recall', 'f1']].mean()\n",
    "level_1_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9269316-1ad0-4bf7-9aa0-faa7fe310ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "level_1_prompt.to_csv(\"results/level-1-prompt-spans.csv\", sep=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
